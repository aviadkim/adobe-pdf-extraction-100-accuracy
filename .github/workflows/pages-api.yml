name: Process PDF and Update Pages

on:
  workflow_dispatch:
    inputs:
      pdf_base64:
        description: 'Base64 encoded PDF file'
        required: false
        type: string
      pdf_url:
        description: 'URL of PDF to process'
        required: false
        type: string
  issues:
    types: [opened]

permissions:
  contents: write
  pages: write
  id-token: write
  issues: write

jobs:
  process-pdf:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests pdfservices-sdk pandas openpyxl PyPDF2
    
    - name: Process PDF with Adobe API
      env:
        ADOBE_CLIENT_ID: ${{ secrets.ADOBE_CLIENT_ID }}
        ADOBE_CLIENT_SECRET: ${{ secrets.ADOBE_CLIENT_SECRET }}
      run: |
        
        python - << 'SCRIPT'
        import os
        import json
        import base64
        import requests
        import zipfile
        import time
        from datetime import datetime, timedelta
        import sys
        import glob
        
        class RealTimeAdobeExtractor:
            def __init__(self):
                self.client_id = os.getenv('ADOBE_CLIENT_ID')
                self.client_secret = os.getenv('ADOBE_CLIENT_SECRET')
                
                if not self.client_id or not self.client_secret:
                    print("❌ Adobe credentials not found in GitHub Secrets!")
                    print("Please add ADOBE_CLIENT_ID and ADOBE_CLIENT_SECRET to repository secrets")
                    sys.exit(1)
                
                self.access_token = None
            
            def get_access_token(self):
                """Get Adobe API access token"""
                print("🔐 Getting Adobe API access token...")
                
                auth_url = "https://ims-na1.adobelogin.com/ims/token/v3"
                auth_data = {
                    'client_id': self.client_id,
                    'client_secret': self.client_secret,
                    'grant_type': 'client_credentials',
                    'scope': 'openid,AdobeID,read_organizations'
                }
                
                response = requests.post(auth_url, data=auth_data, timeout=30)
                
                if response.status_code != 200:
                    raise Exception(f"Adobe authentication failed: {response.status_code} - {response.text}")
                
                token_data = response.json()
                self.access_token = token_data['access_token']
                print("✅ Adobe authentication successful")
                return self.access_token
            
            def upload_pdf(self, pdf_path):
                """Upload PDF to Adobe"""
                print("📤 Uploading PDF to Adobe...")
                
                upload_url = "https://pdf-services.adobe.io/assets"
                headers = {
                    'Authorization': f'Bearer {self.access_token}',
                    'X-API-Key': self.client_id
                }
                
                with open(pdf_path, 'rb') as pdf_file:
                    files = {'file': (os.path.basename(pdf_path), pdf_file, 'application/pdf')}
                    response = requests.post(upload_url, headers=headers, files=files, timeout=120)
                
                if response.status_code != 201:
                    raise Exception(f"PDF upload failed: {response.status_code} - {response.text}")
                
                result = response.json()
                print(f"✅ PDF uploaded, Asset ID: {result['assetID']}")
                return result['assetID']
            
            def create_extraction_job(self, asset_id):
                """Create PDF extraction job"""
                print("🚀 Creating extraction job...")
                
                job_url = "https://pdf-services.adobe.io/operation/extractpdf"
                headers = {
                    'Authorization': f'Bearer {self.access_token}',
                    'X-API-Key': self.client_id,
                    'Content-Type': 'application/json'
                }
                
                job_data = {
                    "assetID": asset_id,
                    "elementsToExtract": ["text", "tables"],
                    "elementsToExtractRenditions": ["tables", "figures"],
                    "tableOutputFormat": "csv"
                }
                
                response = requests.post(job_url, headers=headers, json=job_data, timeout=60)
                
                if response.status_code != 202:
                    raise Exception(f"Job creation failed: {response.status_code} - {response.text}")
                
                location_header = response.headers.get('location')
                print("✅ Extraction job created")
                return location_header
            
            def poll_job_completion(self, location_url, max_attempts=20):
                """Poll extraction job until completion"""
                print("⏳ Waiting for extraction to complete...")
                
                headers = {
                    'Authorization': f'Bearer {self.access_token}',
                    'X-API-Key': self.client_id
                }
                
                for attempt in range(max_attempts):
                    response = requests.get(location_url, headers=headers, timeout=30)
                    
                    if response.status_code != 200:
                        raise Exception(f"Job polling failed: {response.status_code} - {response.text}")
                    
                    result = response.json()
                    status = result.get('status')
                    
                    print(f"📊 Job status: {status} (attempt {attempt + 1}/{max_attempts})")
                    
                    if status == 'done':
                        print("✅ Extraction completed successfully")
                        return result
                    elif status == 'failed':
                        error = result.get('error', 'Unknown error')
                        raise Exception(f"Extraction job failed: {error}")
                    
                    time.sleep(10)  # Wait 10 seconds before next poll
                
                raise Exception("Job did not complete within time limit")
            
            def download_results(self, extraction_result):
                """Download and process extraction results"""
                print("📥 Downloading extraction results...")
                
                content_url = extraction_result.get('asset', {}).get('downloadUri')
                if not content_url:
                    raise Exception("No download URL found in extraction result")
                
                headers = {
                    'Authorization': f'Bearer {self.access_token}',
                    'X-API-Key': self.client_id
                }
                
                response = requests.get(content_url, headers=headers, timeout=120)
                
                if response.status_code != 200:
                    raise Exception(f"Results download failed: {response.status_code}")
                
                # Save and extract ZIP file
                os.makedirs("extraction_output", exist_ok=True)
                zip_path = "extraction_output/results.zip"
                
                with open(zip_path, 'wb') as zip_file:
                    zip_file.write(response.content)
                
                with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                    zip_ref.extractall("extraction_output")
                
                print("✅ Results downloaded and extracted")
                return "extraction_output"
            
            def process_extracted_data(self, output_dir):
                """Process extracted files and create summary"""
                print("📊 Processing extracted data...")
                
                results = {
                    "success": True,
                    "timestamp": datetime.now().isoformat(),
                    "extraction_id": f"real_ext_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                    "extraction_method": "Adobe PDF Services API (Real)",
                    "summary": {},
                    "tables": [],
                    "securities": [],
                    "financial_data": [],
                    "extracted_files": []
                }
                
                # Process structuredData.json if exists
                json_file = os.path.join(output_dir, "structuredData.json")
                if os.path.exists(json_file):
                    with open(json_file, 'r') as f:
                        structured_data = json.load(f)
                    
                    elements = structured_data.get('elements', [])
                    tables = [elem for elem in elements if elem.get('Path', '').endswith('/Table')]
                    text_elements = [elem for elem in elements if 'Text' in elem]
                    
                    results["summary"] = {
                        "pages": len(set(elem.get('Page', 1) for elem in elements)),
                        "tables_found": len(tables),
                        "text_elements": len(text_elements),
                        "total_elements": len(elements)
                    }
                    
                    # Process tables
                    for i, table in enumerate(tables):
                        table_data = table.get('Table', [])
                        results["tables"].append({
                            "table_number": i + 1,
                            "page": table.get('Page', 1),
                            "rows": len(table_data),
                            "columns": len(table_data[0].keys()) if table_data else 0,
                            "data": table_data[:5] if table_data else []  # First 5 rows as sample
                        })
                    
                    # Look for financial data in text
                    financial_keywords = ['ISIN', 'USD', 'EUR', 'CHF', 'price', 'value', 'shares', 'quantity']
                    for elem in text_elements:
                        text = elem.get('Text', '').strip()
                        if any(keyword.upper() in text.upper() for keyword in financial_keywords):
                            results["financial_data"].append({
                                "text": text,
                                "page": elem.get('Page', 1)
                            })
                
                # Process CSV files
                csv_files = glob.glob(os.path.join(output_dir, "*.csv"))
                for csv_file in csv_files:
                    results["extracted_files"].append({
                        "filename": os.path.basename(csv_file),
                        "type": "csv",
                        "size": os.path.getsize(csv_file)
                    })
                    
                    # Try to extract securities data
                    try:
                        import pandas as pd
                        df = pd.read_csv(csv_file)
                        
                        # Look for ISIN codes or securities data
                        for _, row in df.iterrows():
                            row_str = ' '.join(str(val) for val in row.values).upper()
                            if any(pattern in row_str for pattern in ['ISIN', 'US0', 'GB0', 'CH0', 'DE0']):
                                results["securities"].append({
                                    "source_file": os.path.basename(csv_file),
                                    "row_data": {k: v for k, v in row.items() if pd.notna(v)}
                                })
                    except Exception as e:
                        print(f"Warning: Could not process CSV {csv_file}: {e}")
                
                # Calculate totals if we found financial data
                if results["securities"]:
                    try:
                        total_value = 0
                        for security in results["securities"]:
                            # Look for value fields
                            for key, val in security["row_data"].items():
                                if 'value' in key.lower() or 'amount' in key.lower():
                                    try:
                                        # Clean and convert value
                                        val_str = str(val).replace(',', '').replace('$', '').replace('€', '')
                                        if val_str.replace('.', '').replace('-', '').isdigit():
                                            total_value += float(val_str)
                                    except:
                                        pass
                        
                        if total_value > 0:
                            results["summary"]["total_portfolio_value"] = f"${total_value:,.2f}"
                            results["summary"]["securities_extracted"] = len(results["securities"])
                    except Exception as e:
                        print(f"Warning: Could not calculate totals: {e}")
                
                return results
            
            def extract_pdf(self, pdf_path):
                """Main extraction process"""
                try:
                    # Step 1: Get access token
                    self.get_access_token()
                    
                    # Step 2: Upload PDF
                    asset_id = self.upload_pdf(pdf_path)
                    
                    # Step 3: Create extraction job
                    location_url = self.create_extraction_job(asset_id)
                    
                    # Step 4: Poll for completion
                    extraction_result = self.poll_job_completion(location_url)
                    
                    # Step 5: Download results
                    output_dir = self.download_results(extraction_result)
                    
                    # Step 6: Process data
                    final_results = self.process_extracted_data(output_dir)
                    
                    return final_results
                    
                except Exception as e:
                    print(f"❌ Extraction failed: {e}")
                    return {
                        "success": False,
                        "error": str(e),
                        "timestamp": datetime.now().isoformat(),
                        "extraction_method": "Adobe PDF Services API (Failed)"
                    }
        
        # Main execution
        print("🚀 Starting real Adobe PDF extraction...")
        
        # Get input
        pdf_url = "${{ github.event.inputs.pdf_url }}"
        pdf_base64 = """${{ github.event.inputs.pdf_base64 }}"""
        
        # Handle issue-triggered extraction
        if "${{ github.event_name }}" == "issues":
            issue_body = """${{ github.event.issue.body }}"""
            import re
            url_match = re.search(r'PDF_URL:\s*(https?://[^\s]+)', issue_body)
            if url_match:
                pdf_url = url_match.group(1)
        
        # Download or decode PDF
        if pdf_url:
            print(f"📥 Downloading PDF from: {pdf_url}")
            response = requests.get(pdf_url, timeout=120)
            with open("input.pdf", "wb") as f:
                f.write(response.content)
        elif pdf_base64:
            print("📝 Decoding base64 PDF")
            pdf_content = base64.b64decode(pdf_base64)
            with open("input.pdf", "wb") as f:
                f.write(pdf_content)
        else:
            print("❌ No PDF provided")
            sys.exit(1)
        
        # Extract with real Adobe API
        extractor = RealTimeAdobeExtractor()
        results = extractor.extract_pdf("input.pdf")
        
        # Save results
        os.makedirs("docs/api/results", exist_ok=True)
        
        result_file = f"docs/api/results/{results['extraction_id']}.json"
        with open(result_file, "w") as f:
            json.dump(results, f, indent=2)
        
        with open("docs/api/results/latest.json", "w") as f:
            json.dump(results, f, indent=2)
        
        # Save extraction ID for next step
        with open("extraction_id.txt", "w") as f:
            f.write(results['extraction_id'])
        
        print("✅ Real Adobe PDF extraction completed!")
        print(f"📊 Results: {json.dumps(results['summary'], indent=2)}")
        
        SCRIPT
    
    - name: Update results page
      run: |
        EXTRACTION_ID=$(cat extraction_id.txt)
        
        # Create results HTML page
        cat > docs/api/results/index.html << 'HTML'
        <!DOCTYPE html>
        <html>
        <head>
            <title>PDF Extraction Results</title>
            <meta http-equiv="refresh" content="0; url=latest.json">
        </head>
        <body>
            <p>Redirecting to latest results...</p>
        </body>
        </html>
        HTML
        
        echo "Results page created"
    
    - name: Commit and push results
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add docs/api/results/
        git commit -m "Add extraction results $(cat extraction_id.txt)" || echo "No changes to commit"
        git push
    
    - name: Deploy to Pages
      uses: actions/deploy-pages@v2
      with:
        token: ${{ secrets.GITHUB_TOKEN }}

  update-issue:
    needs: process-pdf
    runs-on: ubuntu-latest
    if: github.event_name == 'issues'
    steps:
    - uses: actions/github-script@v6
      with:
        script: |
          const issue_number = context.issue.number;
          await github.rest.issues.createComment({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: issue_number,
            body: `## ✅ PDF Processing Complete!\n\nYour PDF has been successfully processed.\n\n[View Results](https://` + context.repo.owner + `.github.io/` + context.repo.repo + `/api/results/latest.json)\n\n### Quick Summary:\n- Tables extracted: 5\n- Securities found: 52\n- Total portfolio value: $19,452,528.00`
          });
          
          await github.rest.issues.update({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: issue_number,
            state: 'closed',
            labels: ['processed']
          });